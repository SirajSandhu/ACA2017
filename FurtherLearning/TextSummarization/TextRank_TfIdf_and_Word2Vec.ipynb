{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "document = \"\"\"To Sherlock Holmes she is always the woman. I have\n",
    "seldom heard him mention her under any other name. In his eyes she\n",
    "eclipses and predominates the whole of her sex. It was not that he\n",
    "felt any emotion akin to love for Irene Adler. All emotions, and that\n",
    "one particularly, were abhorrent to his cold, precise but admirably\n",
    "balanced mind. He was, I take it, the most perfect reasoning and\n",
    "observing machine that the world has seen, but as a lover he would\n",
    "have placed himself in a false position. He never spoke of the softer\n",
    "passions, save with a gibe and a sneer. They were admirable things for\n",
    "the observer-excellent for drawing the veil from menâ€™s motives and\n",
    "actions. But for the trained reasoner to admit such intrusions into\n",
    "his own delicate and finely adjusted temperament was to introduce a\n",
    "distracting factor which might throw a doubt upon all his mental\n",
    "results. Grit in a sensitive instrument, or a crack in one of his own\n",
    "high-power lenses, would not be more disturbing than a strong emotion\n",
    "in a nature such as his. And yet there was but one woman to him, and\n",
    "that woman was the late Irene Adler, of dubious and questionable\n",
    "memory.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
    "\n",
    "sentence_tokenizer = PunktSentenceTokenizer()\n",
    "sentences_original = sentence_tokenizer.tokenize(\" \".join(document.strip().split(\"\\n\")))\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "\n",
    "document = document.lower().split()\n",
    "document = [w for w in document if not w in stops]\n",
    "\n",
    "document = \" \".join(document)\n",
    "\n",
    "document = \" \".join(document.strip().split(\"\\n\"))\n",
    "\n",
    "sentences = sentence_tokenizer.tokenize(document)\n",
    "\n",
    "import re\n",
    "\n",
    "for i in xrange(0, len(sentences)) :\n",
    "    sentences[i] = re.sub(\"[^a-zA-Z]\", \" \", sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec.load(\"~/Desktop/PClub_DTC/NLP_Learning/Kaggle_BagOfWords/300features_40minwords_10context\")\n",
    "\n",
    "index2word_set = set(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "sentence_matrix = []\n",
    "sentence_length = []\n",
    "\n",
    "num_features = 300\n",
    "\n",
    "for sentence in sentences :\n",
    "    num_words = 0\n",
    "    words = sentence.split()\n",
    "    matrix = np.empty(shape=(len(words), 300), dtype=float)\n",
    "    for word in words : \n",
    "        if word in index2word_set :\n",
    "            matrix[num_words] = model[word]\n",
    "            num_words = num_words + 1\n",
    "\n",
    "    extra_rows = len(words) - num_words\n",
    "    \n",
    "    for i in xrange(0, extra_rows) :\n",
    "        matrix = np.delete(matrix, -1, 0)\n",
    "        \n",
    "    sentence_matrix.append(matrix)\n",
    "    sentence_length.append(num_words)\n",
    "    \n",
    "similarity_matrix_wv = np.identity(len(sentence_matrix))\n",
    "\n",
    "for i in xrange(0, len(sentence_matrix)) :\n",
    "    for j in xrange(i+1, len(sentence_matrix)) :\n",
    "        cum_sum = (np.dot(sentence_matrix[0], sentence_matrix[1].T)).sum(axis=0).sum()\n",
    "        cum_sum = (2*cum_sum)/(sentence_length[i] + sentence_length[j])\n",
    "        similarity_matrix_wv[i][j] = cum_sum\n",
    "        similarity_matrix_wv[j][i] = cum_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words = 'english')\n",
    "bow_matrix = vectorizer.fit_transform(sentences_original)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "transformed_matrix = tfidf_transformer.fit_transform(bow_matrix)\n",
    "\n",
    "similarity_matrix_ti = transformed_matrix * transformed_matrix.T\n",
    "similarity_matrix_ti = similarity_matrix_ti.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "similarity_matrix = (similarity_matrix_wv + similarity_matrix_ti)/2\n",
    "\n",
    "import networkx as nx\n",
    "nx_graph = nx.from_numpy_matrix(similarity_matrix)\n",
    "scores = nx.pagerank(nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To Sherlock Holmes she is always the woman.\n",
      "It was not that he felt any emotion akin to love for Irene Adler.\n",
      "And yet there was but one woman to him, and that woman was the late Irene Adler, of dubious and questionable memory.\n"
     ]
    }
   ],
   "source": [
    "ranked = sorted(((scores[i],i) for (i, s) in enumerate(sentences_original)), reverse=True)\n",
    "\n",
    "summary_length = len(sentences)/3\n",
    "ordered_summary_indices = sorted(ranked[i][1] for i in xrange(0, summary_length))\n",
    "\n",
    "for i in ordered_summary_indices :\n",
    "    print sentences_original[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was not that he felt any emotion akin to love for Irene Adler.\n",
      "All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind.\n"
     ]
    }
   ],
   "source": [
    "document_reconstructed = \" \".join(sentences_original)\n",
    "\n",
    "from gensim.summarization import summarize\n",
    "print summarize(document_reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
